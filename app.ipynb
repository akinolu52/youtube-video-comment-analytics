{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T19:35:04.679897Z",
     "start_time": "2025-02-25T19:35:04.678206Z"
    }
   },
   "cell_type": "code",
   "source": "# !pip install google-api-python-client pandas vaderSentiment textblob python-dotenv",
   "id": "1ad45d8261d46969",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T06:52:55.854761Z",
     "start_time": "2025-02-26T06:52:54.984367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from dotenv import load_dotenv\n",
    "from googleapiclient.discovery import build\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "c519ff68a5843a0c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class YouTubeDataFetcher:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the YouTubeDataFetcher object with the API key and output file.\n",
    "        \"\"\"\n",
    "        self.api_key = os.getenv('YOUTUBE_API_KEY')\n",
    "        self.output_file = 'youtube_data.csv'\n",
    "        self.youtube = self.get_youtube_client()\n",
    "        self.headers = [\"video_id\", \"title\", \"description\", \"view_count\", \"like_count\",\n",
    "                        \"dislike_count\", \"comment_count\", \"duration\", \"favorite_count\", \"comments\", \"sentiment_score\"]\n",
    "\n",
    "        # Load existing processed video IDs\n",
    "        self.processed_video_ids = self.load_processed_video_ids()\n",
    "\n",
    "        # Initialize CSV file (with headers)\n",
    "        try:\n",
    "            with open(self.output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.DictWriter(file, fieldnames=self.headers)\n",
    "                writer.writeheader()\n",
    "        except FileNotFoundError:\n",
    "            print(\"Could not create output file.\")\n",
    "\n",
    "    def get_youtube_client(self):\n",
    "        \"\"\"\n",
    "        Initializes and returns the YouTube API client.\n",
    "        \"\"\"\n",
    "        return build(\"youtube\", \"v3\", developerKey=self.api_key)\n",
    "\n",
    "    def load_processed_video_ids(self):\n",
    "        \"\"\"\n",
    "        Loads the list of processed video IDs from the output CSV file.\n",
    "        Returns a set of video IDs that have already been processed.\n",
    "        \"\"\"\n",
    "        processed_ids = set()\n",
    "        try:\n",
    "            df = pd.read_csv(self.output_file)\n",
    "            processed_ids = set(df['video_id'].values)\n",
    "        except FileNotFoundError:\n",
    "            pass  # If the file doesn't exist yet, just return an empty set\n",
    "        return processed_ids\n",
    "\n",
    "    def fetch_video_data(self, video_id):\n",
    "        \"\"\"\n",
    "        Fetches the video details (views, likes, comments) and comments for the given video_id.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Get the video details (view count, like count, etc.)\n",
    "            video_response = self.youtube.videos().list(\n",
    "                part=\"snippet,statistics,contentDetails\",\n",
    "                id=video_id\n",
    "            ).execute()\n",
    "\n",
    "            if not video_response[\"items\"]:\n",
    "                raise Exception(f\"No video found for ID: {video_id}\")\n",
    "\n",
    "            video_info = video_response[\"items\"][0]\n",
    "            title = video_info[\"snippet\"][\"title\"]\n",
    "            description = video_info[\"snippet\"].get(\"description\", \"No description\")\n",
    "            view_count = int(video_info[\"statistics\"].get(\"viewCount\", 0))\n",
    "            like_count = int(video_info[\"statistics\"].get(\"likeCount\", 0))\n",
    "            dislike_count = int(video_info[\"statistics\"].get(\"dislikeCount\", 0))\n",
    "            comment_count = int(video_info[\"statistics\"].get(\"commentCount\", 0))\n",
    "            duration = video_info[\"contentDetails\"][\"duration\"]\n",
    "            favorite_count = int(video_info[\"statistics\"].get(\"favoriteCount\", 0))\n",
    "\n",
    "            # Fetching comments (max 100 comments)\n",
    "            comments = []\n",
    "            comment_response = self.youtube.commentThreads().list(\n",
    "                part=\"snippet\",\n",
    "                videoId=video_id,\n",
    "                maxResults=100\n",
    "            ).execute()\n",
    "\n",
    "            for item in comment_response[\"items\"]:\n",
    "                comment_text = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "                comments.append(comment_text)\n",
    "\n",
    "            return {\n",
    "                \"video_id\": video_id,\n",
    "                \"title\": title,\n",
    "                \"description\": description,\n",
    "                \"view_count\": view_count,\n",
    "                \"like_count\": like_count,\n",
    "                \"dislike_count\": dislike_count,\n",
    "                \"comment_count\": comment_count,\n",
    "                \"duration\": duration,\n",
    "                \"favorite_count\": favorite_count,\n",
    "                \"comments\": comments\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {video_id}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def analyze_sentiment(comments):\n",
    "        \"\"\"\n",
    "        Analyzes the sentiment of the provided comments using VADER Sentiment Analysis.\n",
    "        Returns a sentiment score.\n",
    "        \"\"\"\n",
    "        analyzer = SentimentIntensityAnalyzer()\n",
    "        sentiment_score = 0\n",
    "        num_comments = len(comments)\n",
    "\n",
    "        for comment in comments:\n",
    "            sentiment = analyzer.polarity_scores(comment)\n",
    "            sentiment_score += sentiment['compound']\n",
    "\n",
    "        # Calculate the average sentiment score\n",
    "        if num_comments > 0:\n",
    "            sentiment_score /= num_comments\n",
    "        return sentiment_score\n",
    "\n",
    "    def save_to_csv(self, video_data):\n",
    "        \"\"\"\n",
    "        Saves the fetched video data into the CSV file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(self.output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.DictWriter(file, fieldnames=self.headers)\n",
    "                writer.writerow({\n",
    "                    \"video_id\": video_data[\"video_id\"],\n",
    "                    \"title\": video_data[\"title\"],\n",
    "                    \"description\": video_data[\"description\"],\n",
    "                    \"view_count\": video_data[\"view_count\"],\n",
    "                    \"like_count\": video_data[\"like_count\"],\n",
    "                    \"dislike_count\": video_data[\"dislike_count\"],\n",
    "                    \"comment_count\": video_data[\"comment_count\"],\n",
    "                    \"duration\": video_data[\"duration\"],\n",
    "                    \"favorite_count\": video_data[\"favorite_count\"],\n",
    "                    \"comments\": \" | \".join(video_data[\"comments\"]),\n",
    "                    \"sentiment_score\": video_data[\"sentiment_score\"]\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving data for {video_data['video_id']}: {str(e)}\")\n",
    "\n",
    "    def fetch_and_process_data(self, df):\n",
    "        \"\"\"\n",
    "        Fetches and processes data for each video in the provided DataFrame.\n",
    "        Saves the results into a CSV file.\n",
    "        \"\"\"\n",
    "        for index, row in df.iterrows():\n",
    "            video_id = row['youtubeId']\n",
    "\n",
    "            # Skip the video if it's already processed\n",
    "            if video_id in self.processed_video_ids:\n",
    "                print(f\"Skipping already processed video: {video_id}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"{index}. Processing video: {video_id}\")\n",
    "\n",
    "            # Fetch video data\n",
    "            video_data = self.fetch_video_data(video_id)\n",
    "\n",
    "            if video_data:\n",
    "                # Analyze sentiment of the comments\n",
    "                sentiment_score = self.analyze_sentiment(video_data[\"comments\"])\n",
    "                video_data[\"sentiment_score\"] = sentiment_score\n",
    "\n",
    "                # Save the data to the CSV file\n",
    "                self.save_to_csv(video_data)\n",
    "\n",
    "            # Sleep to avoid rate-limiting\n",
    "            time.sleep(4)  # Adjust the sleep time as needed to prevent rate limit errors\n",
    "\n",
    "        print(f\"Data fetching and saving complete. All data saved in {self.output_file}.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_wordcloud(df):\n",
    "        \"\"\"\n",
    "        Generates a word cloud from the comments of all videos.\n",
    "        \"\"\"\n",
    "        all_comments = \" \".join(df[\"comments\"].dropna())\n",
    "        wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_comments)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_graphs(df):\n",
    "        \"\"\"\n",
    "        Generates various plots for video statistics using Plotly Express.\n",
    "        \"\"\"\n",
    "        # Top 10 most viewed videos\n",
    "        top_10 = df.nlargest(10, \"view_count\")\n",
    "        fig = px.bar(top_10, x='title', y='view_count', title='Top 10 Most Viewed Videos')\n",
    "        fig.show()\n",
    "\n",
    "        # Bottom 10 least viewed videos\n",
    "        bottom_10 = df.nsmallest(10, \"view_count\")\n",
    "        fig = px.bar(bottom_10, x='title', y='view_count', title='Bottom 10 Least Viewed Videos')\n",
    "        fig.show()\n",
    "\n",
    "        # Most liked video\n",
    "        most_liked = df.loc[df['like_count'].idxmax()]\n",
    "        fig = px.bar(x=[most_liked['title']], y=[most_liked['like_count']], title='Most Liked Video')\n",
    "        fig.show()\n",
    "\n",
    "        # Least liked video\n",
    "        least_liked = df.loc[df['like_count'].idxmin()]\n",
    "        fig = px.bar(x=[least_liked['title']], y=[least_liked['like_count']], title='Least Liked Video')\n",
    "        fig.show()\n",
    "\n",
    "        # Video with the highest duration\n",
    "        highest_duration = df.loc[df['duration'].idxmax()]\n",
    "        fig = px.bar(x=[highest_duration['title']], y=[highest_duration['duration']],\n",
    "                     title='Video with Highest Duration')\n",
    "        fig.show()\n",
    "\n",
    "\n",
    "# Load the CSV containing the video data (e.g., vdoLinks.csv)\n",
    "df = pd.read_csv('vdoLinks.csv')\n",
    "\n",
    "# Create an instance of YouTubeDataFetcher and process the data\n",
    "fetcher = YouTubeDataFetcher()\n",
    "fetcher.fetch_and_process_data(df)\n",
    "\n",
    "# After fetching and saving the data, generate the word cloud and plots\n",
    "fetcher.generate_wordcloud(df)\n",
    "fetcher.generate_graphs(df)\n"
   ],
   "id": "12e12cbab0984320",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d955def439f2766"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (yenv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
